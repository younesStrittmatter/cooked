{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f56a6caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# GRAPH SETTINGS\n",
    "plt.rcParams['mathtext.fontset'] = 'stix'\n",
    "plt.rcParams['font.family'] = 'STIXGeneral'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32991b7b",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d177eb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directorios base\n",
    "local = '/mnt/lustre/home/samuloza'\n",
    "#local = 'C:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado'\n",
    "base_dirs = {\n",
    "    \"Competitive\": f\"{local}/data/samuel_lozano/cooked/map_kitchen/competitive\",\n",
    "    \"Cooperative\": f\"{local}/data/samuel_lozano/cooked/map_kitchen/cooperative\"\n",
    "}\n",
    "\n",
    "output_path = f\"{local}/data/samuel_lozano/cooked/map_kitchen/training_results.csv\"\n",
    "\n",
    "# Eliminar el archivo CSV si ya existe\n",
    "if os.path.exists(output_path):\n",
    "    os.remove(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4157bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dfs = []\n",
    "\n",
    "# Patrón para capturar los coeficientes de recompensa\n",
    "reward_pattern = re.compile(\n",
    "    r\"'([^']+)':\\s*\\(\\s*([-\\d\\.eE+]+),\\s*([-\\d\\.eE+]+)\\)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6741c359",
   "metadata": {},
   "outputs": [],
   "source": [
    "for game_type, base_dir in base_dirs.items():\n",
    "    game_flag = 1 if \"Cooperative\" in game_type else 0\n",
    "    for folder in os.listdir(base_dir):\n",
    "        folder_path = os.path.join(base_dir, folder)\n",
    "        if not os.path.isdir(folder_path):\n",
    "            continue\n",
    "\n",
    "        date_time_str = folder.replace(\"Training_\", \"\")\n",
    "        config_path = os.path.join(folder_path, \"config.txt\")\n",
    "        csv_path = os.path.join(folder_path, \"training_stats.csv\")\n",
    "\n",
    "        if not (os.path.exists(config_path) and os.path.exists(csv_path)):\n",
    "            continue\n",
    "\n",
    "        with open(config_path, \"r\") as f:\n",
    "            config_contents = f.read()\n",
    "        match = reward_pattern.findall(config_contents)\n",
    "        if not match:\n",
    "            continue\n",
    "\n",
    "        (name_1, alpha_1, beta_1), (name_2, alpha_2, beta_2) = match\n",
    "        alpha_1, beta_1 = float(alpha_1), float(beta_1) \n",
    "        alpha_2, beta_2 = float(alpha_2), float(beta_2)\n",
    "\n",
    "        lr_match = re.search(r\"LR:\\s*([0-9.eE+-]+)\", config_contents)\n",
    "        lr = float(lr_match.group(1)) \n",
    "\n",
    "        with open(csv_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        header = lines[0]\n",
    "        filtered_lines = [header] + [line for line in lines[1:] if not line.startswith(\"episode,env\")]\n",
    "\n",
    "        from io import StringIO\n",
    "        df = pd.read_csv(StringIO(\"\".join(filtered_lines)))\n",
    "\n",
    "        df.iloc[:, 0] = range(1, len(df) + 1)\n",
    "\n",
    "        df.insert(0, \"timestamp\", date_time_str)\n",
    "        df.insert(1, \"game_type\", game_flag)\n",
    "        df.insert(2, \"alpha_1\", alpha_1)\n",
    "        df.insert(3, \"beta_1\", beta_1)\n",
    "        df.insert(4, \"alpha_2\", alpha_2)\n",
    "        df.insert(5, \"beta_2\", beta_2)\n",
    "        df.insert(6, \"lr\", lr)\n",
    "\n",
    "        all_dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77888e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenar todos los resultados\n",
    "final_df = pd.concat(all_dfs, ignore_index=True)\n",
    "final_df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24023d0f",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0966578",
   "metadata": {},
   "outputs": [],
   "source": [
    "local = '/mnt/lustre/home/samuloza'\n",
    "#local = 'C:/OneDrive - Universidad Complutense de Madrid (UCM)/Doctorado'\n",
    "base_dirs = {\n",
    "    \"Competitive\": f\"{local}/data/samuel_lozano/cooked/map_kitchen/competitive\",\n",
    "    \"Cooperative\": f\"{local}/data/samuel_lozano/cooked/map_kitchen/cooperative\"\n",
    "}\n",
    "\n",
    "output_path = f\"{local}/data/samuel_lozano/cooked/map_kitchen/training_results.csv\"\n",
    "\n",
    "# Leer el CSV especificando los tipos de datos\n",
    "dtype_dict = {\n",
    "    \"timestamp\": str,\n",
    "    \"game_type\": int,\n",
    "    \"alpha_1\": float,\n",
    "    \"beta_1\": float,\n",
    "    \"alpha_2\": float,\n",
    "    \"beta_2\": float\n",
    "}\n",
    "\n",
    "df = pd.read_csv(output_path, dtype=dtype_dict, low_memory=False)\n",
    "for col in df.columns[6:]:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# Crear una columna identificadora de combinación de coeficientes\n",
    "df = df.sort_values(by=[\"alpha_1\", \"alpha_2\"], ascending=[False, False])\n",
    "df[\"attitude_key\"] = df.apply(lambda row: f\"{row['alpha_1']}_{row['beta_1']}_{row['alpha_2']}_{row['beta_2']}\", axis=1)\n",
    "df[\"pure_reward_total\"] = df[\"pure_reward_ai_rl_1\"] + df[\"pure_reward_ai_rl_2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4aefc31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar todas las combinaciones únicas\n",
    "unique_attitudes = df[\"attitude_key\"].unique()\n",
    "unique_lr = df[\"lr\"].unique()\n",
    "unique_game_type = df[\"game_type\"].unique()\n",
    "\n",
    "figures_dir = f\"{local}/data/samuel_lozano/cooked/map_kitchen/figures/\"\n",
    "os.makedirs(figures_dir, exist_ok=True)\n",
    "\n",
    "rewarded_metrics_1 = [\n",
    "    \"delivered_ai_rl_1\",\n",
    "    \"cut_ai_rl_1\",\n",
    "    \"salad_ai_rl_1\",\n",
    "]\n",
    "\n",
    "rewarded_metrics_2 = [\n",
    "    \"delivered_ai_rl_2\",\n",
    "    \"cut_ai_rl_2\",\n",
    "    \"salad_ai_rl_2\",\n",
    "]\n",
    "\n",
    "metrics_1 = [\n",
    "    \"floor_actions_ai_rl_1\",\n",
    "    \"wall_actions_ai_rl_1\",\n",
    "    \"counter_actions_ai_rl_1\",\n",
    "    \"dispenser_actions_ai_rl_1\",\n",
    "    \"cutting_board_actions_ai_rl_1\",\n",
    "    \"delivery_actions_ai_rl_1\"\n",
    "]\n",
    "\n",
    "metrics_2 = [\n",
    "    \"floor_actions_ai_rl_2\",\n",
    "    \"wall_actions_ai_rl_2\",\n",
    "    \"counter_actions_ai_rl_2\",\n",
    "    \"dispenser_actions_ai_rl_2\",\n",
    "    \"cutting_board_actions_ai_rl_2\",\n",
    "    \"delivery_actions_ai_rl_2\"\n",
    "]\n",
    "\n",
    "rewarded_metric_labels = {\n",
    "    \"delivered_ai_rl_1\": \"Delivered\",\n",
    "    \"cut_ai_rl_1\": \"Cut\",\n",
    "    \"salad_ai_rl_1\": \"Salad\"\n",
    "}\n",
    "\n",
    "metric_labels = {\n",
    "    \"floor_actions_ai_rl_1\": \"Floor\",\n",
    "    \"wall_actions_ai_rl_1\": \"Wall\",\n",
    "    \"counter_actions_ai_rl_1\": \"Counter\",\n",
    "    \"dispenser_actions_ai_rl_1\": \"Dispenser\",\n",
    "    \"cutting_board_actions_ai_rl_1\": \"Cutting Board\",\n",
    "    \"delivery_actions_ai_rl_1\": \"Delivery\"\n",
    "}\n",
    "\n",
    "rewarded_metric_colors = {\n",
    "    \"delivered_ai_rl_1\": \"#27AE60\",\n",
    "    \"cut_ai_rl_1\": \"#E74C3C\",\n",
    "    \"salad_ai_rl_1\": \"#9B59B6\"\n",
    "}\n",
    "\n",
    "metric_colors = {\n",
    "    \"floor_actions_ai_rl_1\": \"#27AE60\",\n",
    "    \"wall_actions_ai_rl_1\": \"#E74C3C\",\n",
    "    \"counter_actions_ai_rl_1\": \"#9B59B6\",\n",
    "    \"dispenser_actions_ai_rl_1\": \"#A0522D\",\n",
    "    \"cutting_board_actions_ai_rl_1\": \"#95A5A6\",\n",
    "    \"delivery_actions_ai_rl_1\": \"#95A5A6\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdb9a24",
   "metadata": {},
   "source": [
    "## General visuals (not smoothed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7361c648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Pure total reward vs epoch\n",
    "\n",
    "for attitude in unique_attitudes:\n",
    "    subset = df[df[\"attitude_key\"] == attitude]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    for game_type in unique_game_type:\n",
    "        game_type_filtered = subset[subset[\"game_type\"] == game_type]\n",
    "    \n",
    "        # Filtrar por tasa de aprendizaje\n",
    "        for lr in unique_lr:\n",
    "            lr_filtered = game_type_filtered[game_type_filtered[\"lr\"] == lr]\n",
    "            grouped = lr_filtered.groupby(\"epoch\")[\"pure_reward_total\"].mean().reset_index()\n",
    "            label = f\"Game Type {game_type}, LR {lr}\"\n",
    "            plt.plot(grouped[\"epoch\"], grouped[\"pure_reward_total\"], label=label)\n",
    "    \n",
    "    # Añadir detalles\n",
    "    plt.title(f\"Pure Reward vs Epoch\\nAttitude {attitude}\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    #plt.xlim([0,100])\n",
    "    plt.ylabel(\"Pure Reward Total\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    sanitized_attitude = attitude.replace('.', 'p')\n",
    "    filename = f\"pure_reward_attitude_{sanitized_attitude}.png\"\n",
    "    filepath = os.path.join(figures_dir, filename)\n",
    "    plt.savefig(filepath)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "479bc358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Each agent pure total reward vs epoch\n",
    "\n",
    "for attitude in unique_attitudes:\n",
    "    subset = df[df[\"attitude_key\"] == attitude]\n",
    "\n",
    "    for game_type in unique_game_type:\n",
    "        game_type_filtered = subset[subset[\"game_type\"] == game_type]\n",
    "    \n",
    "        # Crear la figura\n",
    "        plt.figure(figsize=(10, 6))\n",
    "    \n",
    "        # Filtrar por tasa de aprendizaje\n",
    "        for lr in unique_lr:    \n",
    "            lr_filtered = game_type_filtered[game_type_filtered[\"lr\"] == lr]\n",
    "            grouped = lr_filtered.groupby(\"epoch\")[[\"pure_reward_ai_rl_1\", \"pure_reward_ai_rl_2\"]].mean().reset_index()\n",
    "            label_0 = f\"Agent 1, LR {lr}\"\n",
    "            label_1 = f\"Agent 2, LR {lr}\"\n",
    "            plt.plot(grouped[\"epoch\"], grouped[\"pure_reward_ai_rl_1\"], label=label_0)\n",
    "            plt.plot(grouped[\"epoch\"], grouped[\"pure_reward_ai_rl_2\"], label=label_1)\n",
    "    \n",
    "        # Añadir detalles\n",
    "        plt.title(f\"Pure Reward vs Epoch\\nAttitude {attitude}, Game Type {game_type}\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        #plt.xlim([0,100])\n",
    "        plt.ylabel(\"Pure Reward Total\")\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        sanitized_attitude = attitude.replace('.', 'p')\n",
    "        filename = f\"pure_reward_agents_g{game_type}_attitude_{sanitized_attitude}.png\"\n",
    "        filepath = os.path.join(figures_dir, filename)\n",
    "        plt.savefig(filepath)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab6773c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print agent metrics vs epoch\n",
    "for attitude in unique_attitudes:\n",
    "    subset = df[df[\"attitude_key\"] == attitude]\n",
    "\n",
    "    att_parts = attitude.split('_')\n",
    "    att0_title = f\"{att_parts[0]}_{att_parts[1]}\"\n",
    "    att1_title = f\"{att_parts[2]}_{att_parts[3]}\"\n",
    "\n",
    "    for game_type in [0, 1]:\n",
    "        for lr in subset[\"lr\"].unique():\n",
    "            filtered_subset = subset[(subset[\"game_type\"] == game_type) & (subset[\"lr\"] == lr)]\n",
    "    \n",
    "            plt.figure(figsize=(12, 6))\n",
    "            for metric in rewarded_metrics_1:\n",
    "                grouped = filtered_subset.groupby([\"epoch\"])[metric].mean().reset_index()\n",
    "                plt.plot(grouped[\"epoch\"], grouped[metric], label=metric.replace(\"_\", \" \").title())\n",
    "            plt.title(f\"Metrics per Epoch - Game Type {game_type}, LR {lr}, Attitude {att0_title}\")\n",
    "            plt.xlabel(\"Epoch\")\n",
    "            plt.ylabel(\"Mean value\")\n",
    "            plt.legend()\n",
    "            #plt.xlim([0, 100])\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            sanitized_attitude = attitude.replace('.', 'p')\n",
    "            filename_1 = f\"rewarded_metrics_agent1_g{game_type}_lr{str(lr).replace('.', 'p')}_attitude_{sanitized_attitude}.png\"\n",
    "            filepath_1 = os.path.join(figures_dir, filename_1)\n",
    "            plt.savefig(filepath_1)\n",
    "            plt.close()\n",
    "    \n",
    "            plt.figure(figsize=(12, 6))\n",
    "            for metric in rewarded_metrics_2:\n",
    "                grouped = filtered_subset.groupby([\"epoch\"])[metric].mean().reset_index()\n",
    "                plt.plot(grouped[\"epoch\"], grouped[metric], label=metric.replace(\"_\", \" \").title())\n",
    "            plt.title(f\"Metrics per Epoch - Game Type {game_type}, LR {lr}, Attitude {att1_title}\")\n",
    "            plt.xlabel(\"Epoch\")\n",
    "            plt.ylabel(\"Mean value\")\n",
    "            plt.legend()\n",
    "            #plt.xlim([0, 100])\n",
    "            plt.tight_layout()\n",
    "\n",
    "            filename_2 = f\"rewarded_metrics_agent2_g{game_type}_lr{str(lr).replace('.', 'p')}_attitude_{sanitized_attitude}.png\"\n",
    "            filepath_2 = os.path.join(figures_dir, filename_2)\n",
    "            plt.savefig(filepath_2)\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d275b59",
   "metadata": {},
   "source": [
    "# Smoothed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3c811ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 15\n",
    "\n",
    "smoothed_figures_dir = f\"{local}/data/samuel_lozano/cooked/map_kitchen/figures/smoothed_{N}/\"\n",
    "os.makedirs(smoothed_figures_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0e132a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Pure total reward vs epoch\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for game_type in unique_game_type:\n",
    "    game_type_filtered_df = df[df[\"game_type\"] == game_type]\n",
    "\n",
    "    # Filtrar por tasa de aprendizaje\n",
    "    for lr in unique_lr:\n",
    "        lr_filtered_df = game_type_filtered_df[game_type_filtered_df[\"lr\"] == lr]\n",
    "        lr_filtered_df[\"epoch_block\"] = (lr_filtered_df[\"epoch\"] // N)\n",
    "        block_means = lr_filtered_df.groupby(\"epoch_block\")[\"pure_reward_total\"].mean()\n",
    "        middle_epochs = lr_filtered_df.groupby(\"epoch_block\")[\"epoch\"].median()\n",
    "\n",
    "        if game_type == 0:\n",
    "            label = f\"Competitive\"\n",
    "            color = \"red\"\n",
    "        else:\n",
    "            label = f\"Cooperative\"\n",
    "            color = \"green\"\n",
    "        \n",
    "        plt.plot(middle_epochs, block_means, label=label, color=color)\n",
    "\n",
    "# Añadir detalles\n",
    "plt.xlabel(\"Epochs\", fontsize=20)\n",
    "#plt.xlim([0,100])\n",
    "plt.ylabel(\"Mean total reward\", fontsize=20)\n",
    "plt.legend(fontsize=20)\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "plt.tight_layout()\n",
    "\n",
    "filename = f\"pure_reward_smoothed_{N}.png\"\n",
    "filepath = os.path.join(smoothed_figures_dir, filename)\n",
    "plt.savefig(filepath)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "03aae776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Each agent pure total reward vs epoch\n",
    "\n",
    "for game_type in unique_game_type:\n",
    "    game_type_filtered = df[df[\"game_type\"] == game_type]\n",
    "\n",
    "    # Crear la figura\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Filtrar por tasa de aprendizaje\n",
    "    for lr in unique_lr:\n",
    "        lr_filtered = game_type_filtered[game_type_filtered[\"lr\"] == lr]\n",
    "        lr_filtered[\"epoch_block\"] = (lr_filtered[\"epoch\"] // N)\n",
    "        block_means_1 = lr_filtered.groupby(\"epoch_block\")[\"pure_reward_ai_rl_1\"].mean()\n",
    "        block_means_2 = lr_filtered.groupby(\"epoch_block\")[\"pure_reward_ai_rl_2\"].mean()\n",
    "        middle_epochs = lr_filtered.groupby(\"epoch_block\")[\"epoch\"].median()\n",
    "\n",
    "        label_1 = f\"Agent 1, LR {lr}\"\n",
    "        label_2 = f\"Agent 2, LR {lr}\"\n",
    "        plt.plot(middle_epochs, block_means_1, label=label_1)\n",
    "        plt.plot(middle_epochs, block_means_2, label=label_2)\n",
    "\n",
    "    # Añadir detalles\n",
    "    plt.title(f\"Pure Reward vs Epoch\\nGame Type {game_type}\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    #plt.xlim([0,100])\n",
    "    plt.ylabel(\"Pure Reward Total\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    filename = f\"pure_reward_agents_g{game_type}_smoothed_{N}.png\"\n",
    "    filepath = os.path.join(smoothed_figures_dir, filename)\n",
    "    plt.savefig(filepath)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182370db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3982513/93969600.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_subset[\"epoch_block\"] = (filtered_subset[\"epoch\"] // N)\n",
      "/tmp/ipykernel_3982513/93969600.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_subset[\"epoch_block\"] = (filtered_subset[\"epoch\"] // N)\n"
     ]
    }
   ],
   "source": [
    "# Print agent rewarded metrics vs epoch\n",
    "\n",
    "for game_type in unique_game_type:\n",
    "    for lr in unique_lr:\n",
    "        filtered_subset = df[(df[\"game_type\"] == game_type) & (df[\"lr\"] == lr)]\n",
    "        filtered_subset[\"epoch_block\"] = (filtered_subset[\"epoch\"] // N)\n",
    "\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        for metric in rewarded_metrics_1:\n",
    "            block_means = filtered_subset.groupby(\"epoch_block\")[[metric]].mean()\n",
    "            middle_epochs = filtered_subset.groupby(\"epoch_block\")[\"epoch\"].median()\n",
    "            plt.plot(middle_epochs, block_means, label=metric.replace(\"_\", \" \").title())\n",
    "        plt.title(f\"Metrics per Epoch - Game Type {game_type}, LR {lr}\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Mean value\")\n",
    "        plt.legend()\n",
    "        #plt.xlim([0, 100])\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        filename_1 = f\"rewarded_metrics_agent1_g{game_type}_lr{str(lr).replace('.', 'p')}_smoothed_{N}.png\"\n",
    "        filepath_1 = os.path.join(smoothed_figures_dir, filename_1)\n",
    "        plt.savefig(filepath_1)\n",
    "        plt.close()\n",
    "    \n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        for metric in rewarded_metrics_2:\n",
    "            block_means = filtered_subset.groupby(\"epoch_block\")[[metric]].mean()\n",
    "            middle_epochs = filtered_subset.groupby(\"epoch_block\")[\"epoch\"].median()\n",
    "            plt.plot(middle_epochs, block_means, label=metric.replace(\"_\", \" \").title())\n",
    "        plt.title(f\"Metrics per Epoch - Game Type {game_type}, LR {lr}\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Mean value\")\n",
    "        plt.legend()\n",
    "        #plt.xlim([0, 100])\n",
    "        plt.tight_layout()\n",
    "\n",
    "        filename_2 = f\"rewarded_metrics_agent2_g{game_type}_lr{str(lr).replace('.', 'p')}_smoothed_{N}.png\"\n",
    "        filepath_2 = os.path.join(smoothed_figures_dir, filename_2)\n",
    "        plt.savefig(filepath_2)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0080c6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3982513/2572494477.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_subset[\"epoch_block\"] = (filtered_subset[\"epoch\"] // N)\n",
      "/tmp/ipykernel_3982513/2572494477.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_subset[\"epoch_block\"] = (filtered_subset[\"epoch\"] // N)\n"
     ]
    }
   ],
   "source": [
    "# Print agent metrics vs epoch\n",
    "\n",
    "for game_type in unique_game_type:\n",
    "    for lr in unique_lr:\n",
    "        filtered_subset = df[(df[\"game_type\"] == game_type) & (df[\"lr\"] == lr)]\n",
    "        filtered_subset[\"epoch_block\"] = (filtered_subset[\"epoch\"] // N)\n",
    "\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        for metric in metrics_1:\n",
    "            block_means = filtered_subset.groupby(\"epoch_block\")[[metric]].mean()\n",
    "            middle_epochs = filtered_subset.groupby(\"epoch_block\")[\"epoch\"].median()\n",
    "            plt.plot(middle_epochs, block_means, label=metric.replace(\"_\", \" \").title())\n",
    "        plt.title(f\"Metrics per Epoch - Game Type {game_type}, LR {lr}\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Mean value\")\n",
    "        plt.legend()\n",
    "        #plt.xlim([0, 100])\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        filename_1 = f\"metrics_agent1_g{game_type}_lr{str(lr).replace('.', 'p')}_smoothed_{N}.png\"\n",
    "        filepath_1 = os.path.join(smoothed_figures_dir, filename_1)\n",
    "        plt.savefig(filepath_1)\n",
    "        plt.close()\n",
    "    \n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        for metric in metrics_2:\n",
    "            block_means = filtered_subset.groupby(\"epoch_block\")[[metric]].mean()\n",
    "            middle_epochs = filtered_subset.groupby(\"epoch_block\")[\"epoch\"].median()\n",
    "            plt.plot(middle_epochs, block_means, label=metric.replace(\"_\", \" \").title())\n",
    "        plt.title(f\"Metrics per Epoch - Game Type {game_type}, LR {lr}\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Mean value\")\n",
    "        plt.legend()\n",
    "        #plt.xlim([0, 100])\n",
    "        plt.tight_layout()\n",
    "\n",
    "        filename_2 = f\"metrics_agent2_g{game_type}_lr{str(lr).replace('.', 'p')}_smoothed_{N}.png\"\n",
    "        filepath_2 = os.path.join(smoothed_figures_dir, filename_2)\n",
    "        plt.savefig(filepath_2)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "18065ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Pure total reward vs epoch\n",
    "for attitude in unique_attitudes:\n",
    "    subset = df[df[\"attitude_key\"] == attitude]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    for game_type in unique_game_type:\n",
    "        game_type_filtered = subset[subset[\"game_type\"] == game_type]\n",
    "    \n",
    "        # Filtrar por tasa de aprendizaje\n",
    "        for lr in unique_lr:\n",
    "            lr_filtered = game_type_filtered[game_type_filtered[\"lr\"] == lr]\n",
    "            lr_filtered[\"epoch_block\"] = (lr_filtered[\"epoch\"] // N)\n",
    "\n",
    "            # Calcular la media de recompensa por bloque\n",
    "            block_means = lr_filtered.groupby(\"epoch_block\")[\"pure_reward_total\"].mean()\n",
    "            middle_epochs = lr_filtered.groupby(\"epoch_block\")[\"epoch\"].median()\n",
    "\n",
    "            if game_type == 0:\n",
    "                label = f\"Competitive\"\n",
    "                color = \"red\"\n",
    "            else:\n",
    "                label = f\"Cooperative\"\n",
    "                color = \"orange\"\n",
    "\n",
    "            plt.plot(middle_epochs, block_means, label=label, color=color)\n",
    "    \n",
    "    # Añadir detalles\n",
    "    plt.xlabel(\"Epochs\", fontsize=20)\n",
    "    #plt.xlim([0,100])\n",
    "    if attitude == \"0.707107_0.707107_0.707107_0.707107\":\n",
    "        plt.title(\"Cooperative agents\", fontsize=24)\n",
    "    elif attitude == \"1.0_0.0_1.0_0.0\":\n",
    "        plt.title(\"Individualistic agents\", fontsize=24)\n",
    "    elif attitude == \"-1.0_0.0_1.0_0.0\":\n",
    "        plt.title(\"Martyr agent with individualistic agent\", fontsize=24)\n",
    "    elif attitude == \"-0.707107_-0.707107_0.707107_0.707107\":\n",
    "        plt.title(\"Destructive agent with cooperative agent\", fontsize=24)\n",
    "\n",
    "    plt.ylabel(\"Mean total reward\", fontsize=20)\n",
    "    plt.legend(fontsize=20)\n",
    "    plt.xticks(fontsize=18)\n",
    "    plt.yticks(fontsize=18)\n",
    "    #plt.ylim(-140, 320)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    sanitized_attitude = attitude.replace('.', 'p')\n",
    "    filename = f\"pure_reward_attitude_{sanitized_attitude}_smoothed_{N}.png\"\n",
    "    filepath = os.path.join(smoothed_figures_dir, filename)\n",
    "    plt.savefig(filepath)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ee8721",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cooked_11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
